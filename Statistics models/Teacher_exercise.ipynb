{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial = {}\n",
    "first_order = {}\n",
    "second_order = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(s):\n",
    "    return s.translate(str.maketrans('','',string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add2dict(dictionary, key, value):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = []\n",
    "    dictionary[key].append(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open('../documents_for_course/Robert_frost.txt'):\n",
    "    tokens = remove_punctuation(line.rstrip().lower()).split()\n",
    "\n",
    "    line_length = len(tokens)\n",
    "    for count in range(line_length):\n",
    "        # print(count)\n",
    "        word = tokens[count]\n",
    "        # print(word)\n",
    "        if count==0:\n",
    "            # If its the first word add a 0 if its not or add one if its there\n",
    "            initial[word] = initial.get(word,0.) + 1\n",
    "        else:\n",
    "            # If it's not the first word take the previous one\n",
    "            t_1 = tokens[count-1]\n",
    "            if count == line_length - 1:\n",
    "                # If its the last word it's added to the dict but it does not have the probability\n",
    "                add2dict(second_order, (t_1,word),'END')\n",
    "            if count ==1:\n",
    "                # If it's the second word we add to the dictionary first_order the previous word as a key and the word as a value\n",
    "                add2dict(first_order,t_1,word)\n",
    "            else:\n",
    "                # If it's not the second word nor the first nor the last we add to the dictionary second_order the previous two words in a tuple format as a key and the word as a value\n",
    "                t_2 = tokens[count-2]\n",
    "                add2dict(second_order, (t_2,t_1),word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We calculate the probabilities for the initial state vectors\n",
    "initial_total = sum(initial.values())\n",
    "for t,c in initial.items():\n",
    "    initial[t] = c / initial_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list2pdict(transition):\n",
    "    # This function creates a dictionary from a list making the counts for wach word and finally dividing by the total size of the possible words in the tranistion\n",
    "    #.items() returns the key value pairs as a tuple \n",
    "    dictionary = {}\n",
    "    n_size = len(transition)\n",
    "    for term in transition:\n",
    "        dictionary[term] = dictionary.get(term,0.) + 1\n",
    "    for term,counter in dictionary.items():\n",
    "        dictionary[term] = counter/ n_size\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the probabilities for the matrix of first order\n",
    "for t_1, transition in first_order.items():\n",
    "    first_order[t_1] = list2pdict(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute the probabilities for the matrix of second order\n",
    "for key, transition in second_order.items():\n",
    "    second_order[key] = list2pdict(transition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_word(dictionary):\n",
    "    #generate a random probability between 0 and 1\n",
    "    p0 = np.random.random()\n",
    "    cumulative = 0\n",
    "    for transition, probability in dictionary.items():\n",
    "        #for each transition in the dictionary of the function check if the limit is less than the cumulative\n",
    "        cumulative += probability\n",
    "        if p0 < cumulative:\n",
    "            # If it's less add the transition (word)\n",
    "            return transition\n",
    "    #It should always return Something this way we make sure that we are returning always something\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate():\n",
    "    # This function will generate stanzas\n",
    "    for i in range(4):\n",
    "        # We're gonna generate stanzas of 4 verses\n",
    "        sentence = []\n",
    "\n",
    "        w0 = sample_word(initial)\n",
    "        sentence.append(w0)\n",
    "        # Use our previous function to take a word from the initial ones\n",
    "        # print(first_order[w0])\n",
    "\n",
    "        w1 = sample_word(first_order[w0])\n",
    "        sentence.append(w1)\n",
    "        # We then use again our function to generate a word form the matrix of first states. Notice that it'll look in the key corresponding to the prevous word\n",
    "\n",
    "        while True:\n",
    "            # We still iterate over the last dictionary unitl we find the ficticious token END that we've created. In that case the verse will be completed.\n",
    "            # Until we find the new word we still iterate and making the new words the previous ones\n",
    "            w2 = sample_word(second_order[(w0,w1)])\n",
    "            if w2 == 'END':\n",
    "                break\n",
    "            sentence.append(w2)\n",
    "            w0 = w1\n",
    "            w1 = w2\n",
    "        print(' '.join(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i went to bed alone and left me\n",
      "might just as empty\n",
      "but it isnt as if and thats not all the money goes so fast\n",
      "you couldnt call it living for it aint\n"
     ]
    }
   ],
   "source": [
    "generate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0201f44e18421a348372a57be9a6ecc536ca8ed47d3c72bd26e81ed63defa3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
