{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having a created dataset generate a new sentences and using the theory learned in the markov models calculate the probability of a new sentence that uses words from the training dataset and unseen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Training_dataset = [\"The quick brown fox jumps over the lazy dog\",\n",
    "\"The monkey eat the bananas\",\n",
    "\"The lion sleeps while the crocodile hunts\",\n",
    "\"Bears are omnivores and eat meat and vegetables\",\n",
    "\"I like sentences about animals for my markov model exercise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_size(Training_dataset):\n",
    "    number_of_states = []\n",
    "    for sentence in Training_dataset:\n",
    "        for word in sentence.split(\" \"):\n",
    "            if word not in number_of_states:\n",
    "                number_of_states.append(word)\n",
    "    return number_of_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skeleton_transitions_matrix(Training_dataset):\n",
    "    number_of_states = get_vocabulary_size(Training_dataset)\n",
    "    dictionary_dataframe = {}\n",
    "    for word in number_of_states:\n",
    "        dictionary_dataframe[word] = 1\n",
    "    dataframe_estados = pd.DataFrame(dictionary_dataframe, index=number_of_states)\n",
    "\n",
    "    return dataframe_estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(dataset):\n",
    "    possible_states = get_vocabulary_size(dataset)\n",
    "    dataframe_estados = create_skeleton_transitions_matrix(dataset)\n",
    "    transitions_values = dataframe_estados.to_dict()\n",
    "    number_of_transitions = 0\n",
    "    number_of_appearances_in_dataset_of_state = 0\n",
    "    \n",
    "    for state in range(len(possible_states)):\n",
    "        state_origin = possible_states[state]\n",
    "        for state in range(len(possible_states)):\n",
    "            state_transition = possible_states[state]\n",
    "            for sentence in dataset:\n",
    "                if state_origin in sentence:\n",
    "                    number_of_appearances_in_dataset_of_state +=1\n",
    "                split_sentence = sentence.split(\" \")\n",
    "                for word in range(len(split_sentence)-1):\n",
    "                    if split_sentence[word] == state_origin and split_sentence[word+1] == state_transition:\n",
    "                        number_of_transitions +=1\n",
    "            numerator = number_of_transitions+1\n",
    "            denominator = number_of_appearances_in_dataset_of_state+len(possible_states)\n",
    "            transition_probability = numerator/denominator\n",
    "            transitions_values[state_origin][state_transition] = transition_probability\n",
    "            number_of_appearances_in_dataset_of_state = 0\n",
    "            number_of_transitions = 0\n",
    "    final_matrix = pd.DataFrame(transitions_values)\n",
    "    # check_working_ok = final_matrix['brown'].sum()\n",
    "    # print(check_working_ok)\n",
    "\n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state_probability(sentence, training_dataset):\n",
    "    number_of_initial_state_in_dataset = 0\n",
    "    number_of_sentences_in_dataset = len(training_dataset)\n",
    "    number_of_possible_states = len(get_vocabulary_size(training_dataset))\n",
    "    splitted_sentence = sentence.split(\" \")\n",
    "    initial_word = splitted_sentence[0]\n",
    "    for sentence in training_dataset:\n",
    "        if sentence.startswith(initial_word):\n",
    "            number_of_initial_state_in_dataset +=1\n",
    "    numerator = number_of_initial_state_in_dataset+1\n",
    "    denominator = number_of_sentences_in_dataset+number_of_possible_states\n",
    "    probability_of_initial_state = numerator/denominator\n",
    "        \n",
    "    return probability_of_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_probability(dataset,sentence):\n",
    "    possible_states = get_vocabulary_size(dataset)\n",
    "    probability = initial_state_probability(sentence, dataset)\n",
    "    transitions_matrix = create_transition_matrix(dataset)\n",
    "    splitted_sentence = sentence.split(\" \")\n",
    "    for word in range(len(splitted_sentence)-1):\n",
    "        if word != 0:\n",
    "            if splitted_sentence[word] in possible_states and splitted_sentence[word-1] in possible_states:\n",
    "                transition_probability = transitions_matrix[splitted_sentence[word]][splitted_sentence[word-1]]\n",
    "            else:\n",
    "                transition_probability = 1/len(possible_states)**2\n",
    "            probability = probability * transition_probability\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    #In order to see the number \n",
    "    # probability = probability * 1000000    \n",
    "    return math.log(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juan_\\Desktop\\programación\\NLP_ML_DL_UdemyCourse\\Statistics models\\Markov_model_exercise.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Markov_model_exercise.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_sentence_probability(Training_dataset,\u001b[39m\"\u001b[39;49m\u001b[39mThe rat sleeps over the fox\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\juan_\\Desktop\\programación\\NLP_ML_DL_UdemyCourse\\Statistics models\\Markov_model_exercise.ipynb Cell 9\u001b[0m in \u001b[0;36mget_sentence_probability\u001b[1;34m(dataset, sentence)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Markov_model_exercise.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Markov_model_exercise.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         transition_probability \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39mlen\u001b[39m(possible_states)\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Markov_model_exercise.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     probability \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39;49mlog(probability) \u001b[39m+\u001b[39m math\u001b[39m.\u001b[39mlog(transition_probability)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Markov_model_exercise.ipynb#X11sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Markov_model_exercise.ipynb#X11sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "get_sentence_probability(Training_dataset,\"The rat sleeps over the fox\")\n",
    "# It was -23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-16.413892310911088"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_probability(Training_dataset,\"The Bears sleeps over the fox\")\n",
    "# It was -16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-31.609646651458227"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_probability(Training_dataset,\"Me encantan los perros muy limpios\")\n",
    "# It was -31"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4 (tags/v3.9.4:1f2e308, Apr  6 2021, 13:40:21) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0201f44e18421a348372a57be9a6ecc536ca8ed47d3c72bd26e81ed63defa3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
