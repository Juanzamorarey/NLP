{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the data in two lists that contains the different lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/juan_/Desktop/programación/NLP_ML_DL_UdemyCourse/documents_for_course/Edgar_allan_poe.txt',encoding=\"utf-8\", mode = \"r\") as doc:\n",
    "    poe_dataset = doc.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('C:/Users/juan_/Desktop/programación/NLP_ML_DL_UdemyCourse/documents_for_course/Robert_frost.txt',encoding=\"utf-8\", mode = \"r\") as doc:\n",
    "    frost_dataset = doc.readlines()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that generates a dataframe for each author and split that dataframe into testing and training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_set(dataset):\n",
    "    dataframe_set = pd.DataFrame({'Author': pd.Series(dtype='str'),'Poem': pd.Series(dtype='str')})\n",
    "    for sentence in range(len(dataset)):\n",
    "        list_row = [\"Poe\",dataset[sentence]]\n",
    "        dataframe_set.loc[len(dataframe_set)] = list_row\n",
    "        \n",
    "\n",
    "    training_data = dataframe_set.sample(frac=0.8, random_state=25)\n",
    "    testing_data = dataframe_set.drop(training_data.index)\n",
    "\n",
    "    return training_data, testing_data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate with our function out training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "poe_training_data, poe_testing_data = divide_set(poe_dataset)\n",
    "frost_training_data, frost_testing_data = divide_set(frost_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that, given a specific dataframe, returns a word to index mapping for every word in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_size(dataset):\n",
    "    number_of_states = {}\n",
    "    counter = 0\n",
    "    for index, row in dataset.iterrows():\n",
    "        poem_line = row['Poem']\n",
    "        for word in poem_line.split(\" \"):\n",
    "            if word not in number_of_states:\n",
    "                number_of_states[word] = counter\n",
    "                counter +=1\n",
    "    number_of_states[\"unknown_word\"] = len(number_of_states) + 1\n",
    "    return number_of_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1601\n"
     ]
    }
   ],
   "source": [
    "states_in_poe = get_vocabulary_size(poe_training_data)\n",
    "print(len(states_in_poe))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have to turn every line of text in the training dataset into its respective series of integers from our mapping. \n",
    "Then we create a markov model for each of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_skeleton_transitions_matrix(Training_dataset):\n",
    "    number_of_states = get_vocabulary_size(Training_dataset)\n",
    "    dictionary_dataframe = {}\n",
    "    for word in number_of_states:\n",
    "        dictionary_dataframe[word] = 1\n",
    "    dataframe_estados = pd.DataFrame(dictionary_dataframe, index=number_of_states)\n",
    "\n",
    "    return dataframe_estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_transition_matrix(dataset):\n",
    "    possible_states = get_vocabulary_size(dataset)\n",
    "    dataframe_estados = create_skeleton_transitions_matrix(dataset)\n",
    "    transitions_values = dataframe_estados.to_dict()\n",
    "    number_of_transitions = 0\n",
    "    number_of_appearances_in_dataset_of_state = 0\n",
    "    \n",
    "    for state in range(len(possible_states)):\n",
    "        state_origin = possible_states[state]\n",
    "        for state in range(len(possible_states)):\n",
    "            state_transition = possible_states[state]\n",
    "            for sentence in dataset:\n",
    "                if state_origin in sentence:\n",
    "                    number_of_appearances_in_dataset_of_state +=1\n",
    "                split_sentence = sentence.split(\" \")\n",
    "                for word in range(len(split_sentence)-1):\n",
    "                    if split_sentence[word] == state_origin and split_sentence[word+1] == state_transition:\n",
    "                        number_of_transitions +=1\n",
    "            numerator = number_of_transitions+1\n",
    "            denominator = number_of_appearances_in_dataset_of_state+len(possible_states)\n",
    "            transition_probability = numerator/denominator\n",
    "            transitions_values[state_origin][state_transition] = transition_probability\n",
    "            number_of_appearances_in_dataset_of_state = 0\n",
    "            number_of_transitions = 0\n",
    "    final_matrix = pd.DataFrame(transitions_values)\n",
    "\n",
    "    return final_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_state_probability(sentence, training_dataset):\n",
    "    number_of_initial_state_in_dataset = 0\n",
    "    number_of_sentences_in_dataset = len(training_dataset)\n",
    "    number_of_possible_states = len(get_vocabulary_size(training_dataset))\n",
    "    splitted_sentence = sentence.split(\" \")\n",
    "    initial_word = splitted_sentence[0]\n",
    "    for sentence in training_dataset:\n",
    "        if sentence.startswith(initial_word):\n",
    "            number_of_initial_state_in_dataset +=1\n",
    "    numerator = number_of_initial_state_in_dataset+1\n",
    "    denominator = number_of_sentences_in_dataset+number_of_possible_states\n",
    "    probability_of_initial_state = numerator/denominator\n",
    "        \n",
    "    return probability_of_initial_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_probability(dataset,sentence):\n",
    "    possible_states = get_vocabulary_size(dataset)\n",
    "    probability = initial_state_probability(sentence, dataset)\n",
    "    transitions_matrix = create_transition_matrix(dataset)\n",
    "    splitted_sentence = sentence.split(\" \")\n",
    "    for word in range(len(splitted_sentence)-1):\n",
    "        if word != 0:\n",
    "            if splitted_sentence[word] in possible_states and splitted_sentence[word-1] in possible_states:\n",
    "                transition_probability = transitions_matrix[splitted_sentence[word]][splitted_sentence[word-1]]\n",
    "            else:\n",
    "                transition_probability = 1/len(possible_states)**2\n",
    "            probability = probability * transition_probability\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    return math.log(probability)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_sentence(sentence):\n",
    "    probability_poe = get_sentence_probability(poe_dataset,sentence)\n",
    "    probability_frost = get_sentence_probability(frost_dataset,sentence)\n",
    "    probability_poe = math.log(probability_poe)\n",
    "    probability_frost = math.log(probability_frost)\n",
    "    print(probability_poe)\n",
    "    print(probability_frost)\n",
    "    if probability_poe > probability_frost:\n",
    "        print(\"El texto es de poe\")\n",
    "    else:\n",
    "        print(\"El texto es de frost\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\juan_\\Desktop\\programación\\NLP_ML_DL_UdemyCourse\\Statistics models\\Text_classifier.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m classify_sentence(\u001b[39m\"\"\"\u001b[39;49m\u001b[39mAnd travellers now within that valley,\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mThrough the red-litten windows, see\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mVast forms that move fantastically\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mTo a discordant melody;\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mWhile, like a rapid ghastly river,\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mThrough the pale door,\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mA hideous throng rush out forever,\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mAnd laugh --but smile no more.\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\juan_\\Desktop\\programación\\NLP_ML_DL_UdemyCourse\\Statistics models\\Text_classifier.ipynb Cell 12\u001b[0m in \u001b[0;36mclassify_sentence\u001b[1;34m(sentence)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclassify_sentence\u001b[39m(sentence):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     probability_poe \u001b[39m=\u001b[39m get_sentence_probability(poe_dataset,sentence)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     probability_frost \u001b[39m=\u001b[39m get_sentence_probability(frost_dataset,sentence)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     probability_poe \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mlog(probability_poe)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     probability_frost \u001b[39m=\u001b[39m math\u001b[39m.\u001b[39mlog(probability_frost)\n",
      "\u001b[1;32mc:\\Users\\juan_\\Desktop\\programación\\NLP_ML_DL_UdemyCourse\\Statistics models\\Text_classifier.ipynb Cell 12\u001b[0m in \u001b[0;36mget_sentence_probability\u001b[1;34m(dataset, sentence)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m possible_states \u001b[39m=\u001b[39m get_vocabulary_size(dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m probability \u001b[39m=\u001b[39m initial_state_probability(sentence, dataset)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m transitions_matrix \u001b[39m=\u001b[39m create_transition_matrix(dataset)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m splitted_sentence \u001b[39m=\u001b[39m sentence\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(splitted_sentence)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n",
      "\u001b[1;32mc:\\Users\\juan_\\Desktop\\programación\\NLP_ML_DL_UdemyCourse\\Statistics models\\Text_classifier.ipynb Cell 12\u001b[0m in \u001b[0;36mcreate_transition_matrix\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     number_of_appearances_in_dataset_of_state \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m split_sentence \u001b[39m=\u001b[39m sentence\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(split_sentence)\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mif\u001b[39;00m split_sentence[word] \u001b[39m==\u001b[39m state_origin \u001b[39mand\u001b[39;00m split_sentence[word\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m state_transition:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/juan_/Desktop/programaci%C3%B3n/NLP_ML_DL_UdemyCourse/Statistics%20models/Text_classifier.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         number_of_transitions \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "classify_sentence(\"\"\"And travellers now within that valley,\n",
    "Through the red-litten windows, see\n",
    "Vast forms that move fantastically\n",
    "To a discordant melody;\n",
    "While, like a rapid ghastly river,\n",
    "Through the pale door,\n",
    "A hideous throng rush out forever,\n",
    "And laugh --but smile no more.\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c0201f44e18421a348372a57be9a6ecc536ca8ed47d3c72bd26e81ed63defa3d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
