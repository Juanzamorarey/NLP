{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a construir un clasificador de spam or ham en python, utilizando todo lo que hemos aprendido en la lección."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://lazyprogrammer.me/course_files/spam.csv\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import spacy\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://lazyprogrammer.me/course_files/spam.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = pd.read_csv('spam.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al inspeccionar nuestros datos por encima vemos que se han creado una serie de columnas cuya información no nos interesa. Debido a esto vamos a eliminarlas y quedarnos únicamente con la etiqueta y el texto. Además cambiaremos el nombre de estas columnas para poder visualizar y manejar mejor nuestros datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for columna in df_spam.columns:\n",
    "    if 'Unnamed' in columna:\n",
    "        df_spam = df_spam.drop(columna, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    }
   ],
   "source": [
    "df_spam.head()\n",
    "print(len(df_spam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_spam.rename(columns={'v1':'label','v2':'text'})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora necesitamos una función de preprocesado que reduzca la dimensionalidad del modelo. Para ello vamos a escribir una función de normalización. Esta función lo que hará será pasar todo el texto a minúsculas y eliminar del mismo la puntuación. Después usando una función lambda vamos a aplicar dicha función a toda la columna del dataframe que nos interesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(raw_text):\n",
    "    raw_text = str(raw_text).lower()\n",
    "    text = raw_text.translate(str.maketrans('','',string.punctuation))\n",
    "    return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta línea de abajo funciona de la siguiente manera:\n",
    "\n",
    "para la columna text del df_spam (que es un objeto de tipo Series) le decimos que, dentro de esa serie, a cada elemento x (de aquí viene el lambda x:) le aplique la función normalize_text.\n",
    "\n",
    "Vamos a imprimir un elemento del df_spam para ver que la función se ha aplicado correctamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam['text'] = df_spam['text'].apply(lambda x: normalize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spam['text'][0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perfecto. Nuestros datos de entrenamiento están preparados. Ahora tenemos que hacer el paso siguiente: convertir las palabras a vectores. Para ello se pueden utilizar diferentes métodos. El countVectorizer podría ser una opción pero, dado que tenemos texto natural, es muy probable que las stopwrods y otras palabras sin sgnificado semántico tengan un peso muy superior a aquellas que podrían realmente identificar qué diferencia a spam de ham. Siendo así Hemos oprtado por el vectorizador TfIDF porque reduce el peso de las palabras que aparecen mucho en el dataset.\n",
    "\n",
    "Al vectorizar creamos una matriz enorme en el que están las representaciones numéricas del lenguaje natural del dataset. Cada fila será un documento y cada coumna una palabra. Podemos ver en una celda superior como el primer número coincide en esta matriz con el length del dataframe (5572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 9489)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df_spam['text'])\n",
    "vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a dividir nuestros datos en sets de entrenamiento y test. train_test_split devuelve 4 elementos: \n",
    "\n",
    "1o -> datos de entrenamiento (en este caso vectores que usaremos para entrenar) -> X_train\n",
    "2o -> etiquetas de datos de entrenamiento (indica si ese vector es spam o ham) -> X_test\n",
    "3o -> datos de test (vectores de datos que usaremos para medir la performance) -> y_train\n",
    "4o -> etiquetas de test (indica si el vector es spam o ham) -> y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, df_spam['label'], test_size=0.15, random_state=111)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto del código tenemos ya el dataframe procesado, los vecotres para cada uno de los textos junto a su etiqueta y hemos dividido en dos sets: uno de training y otro de test. Ahora tenemos que elegir un modelo. Esta parte es más complicada y requiere de visualización de datos al mismo tiempo que una comprensión más profunda de cómo funciona cada modelo. Tratándose de un ejercicio como este lo que vamos a hacer es probar diferentes clasificadores que vienen de serie de sklearn y ver qué resultados nos ofrecen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LogisticRegression(solver='liblinear', penalty='l1')\n",
    "model = RandomForestClassifier(n_estimators=31, random_state=111)\n",
    "# model = MultinomialNB(alpha=0.2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a crear dos funciones muy básicas: la primera recibe el modelo, los vecotres de entrenamiento y las etiquetas para los datos. El segundo recibe el modelo entrenado y otros vecotres sobre el que hará predicciones. Después ejecutamos ambas funciones sorbe nuestros datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(variable_with_model, vectors_of_training, labels_of_training):\n",
    "    variable_with_model.fit(vectors_of_training, labels_of_training)\n",
    "\n",
    "def predict(variable_with_model_trained, new_vector):\n",
    "    return (variable_with_model_trained.predict(new_vector))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,X_train,y_train)\n",
    "pred = predict(model,X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genial. Ya tenemos nuestro modelo de ML preparado y realizando predicciones. Ahora tenemos que ver cuan bien lo hace nuestro modelo. Empecemos por mirar la medida más básica: el accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9760765550239234\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test,pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo tiene un accuracy de 96% lo que está bastante bien pero cuidado. No hemos mirado previamente (gran error) si las clases están o no balanceadas. Es decir si hay una muestra representativa suficiente de todas las posibilidades de modo que nuestro modelo pueda generalizar con precision. Necesitamos otras medidas. Para ello nos vamos a valer de lo que vimos en la clase sobre métricas, es decir: matrices de confusión, precision, recall y el F1 score. Estas técnicas nos servirán para ver realmente cuan bien lo está haciendo nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred_nb = model.predict(X_test)\n",
    "y_true_nb = y_test\n",
    "cm = confusion_matrix(y_true_nb, y_pred_nb)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya tenemos nuestra matriz de confusión que tiene el siguiente aspecto:\n",
    "[[718   7]\n",
    " [ 25  86]]\n",
    "\n",
    "Podríamos ahora implementar nosotros mismos las cuentas usando las fórmulas pero sklearn ya las incluye por lo que no habrá necesidad. Pero lo haremos igualmente para ver cuan diferente es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9731543624161074\n",
      "0.9767187951575094\n",
      "0.9750549705883585\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision = cm[0][0] / (cm[0][0]+cm[1][0])\n",
    "print(precision)\n",
    "precision = precision_score(y_true_nb,y_pred_nb,average='weighted')\n",
    "print(precision)\n",
    "F1 = f1_score(y_true_nb,y_pred_nb,average='weighted')\n",
    "print(F1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos la métrica sigue siendo bastante alta por lo que podemos confiar en que este modelo funciona bastante bien. Ya tenemos contruido nuestro clasificador de emailes entre spam o legítimo. De todos los modelos evaluados el que mejor métricas ofrece es el MultinomialNB por lo que en este caso sería el que elegiríamos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
