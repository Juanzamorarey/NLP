{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we open the tweets and take a look at them. We'll see that there are several columns that we don't want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_general_tweets = pd.read_csv('Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_general_tweets.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to keep only the text and the labels so we're gonna create a new df with the columns that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prepared = pd.DataFrame().assign(Label=df_general_tweets['airline_sentiment'],Text=df_general_tweets['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "0   neutral                @VirginAmerica What @dhepburn said.\n",
       "1  positive  @VirginAmerica plus you've added commercials t...\n",
       "2   neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3  negative  @VirginAmerica it's really aggressive to blast...\n",
       "4  negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_prepared.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an optional step but I'm gonna rename the columns to work more comfortably"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_prepared.rename(columns={'airline_sentiment':'label'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "0   neutral                @VirginAmerica What @dhepburn said.\n",
       "1  positive  @VirginAmerica plus you've added commercials t...\n",
       "2   neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3  negative  @VirginAmerica it's really aggressive to blast...\n",
       "4  negative  @VirginAmerica and it's a really big bad thing..."
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're gonna explore the data using seabron. This will help us see if there are imbalance in the classes so we can be aware of this possibility as soon as possible. In order to do so we can make a graph that shows us the number of each type of tweet compared to the total number of tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counts_dict = {'positive':[0],'negative':[0],'neutral':[0]}\n",
    "for i in df['Label']:\n",
    "    if i == \"positive\":\n",
    "        counts_dict['positive'][0] +=1\n",
    "    if i == \"negative\":\n",
    "        counts_dict['negative'][0] +=1\n",
    "    if i == \"neutral\":\n",
    "        counts_dict['neutral'][0] +=1\n",
    "\n",
    "#Exploring dataset:\n",
    "df_plot = pd.DataFrame.from_dict(counts_dict)\n",
    "sns.barplot(data=df_plot)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see our classes are higly imbalanced, we have much more negative tweets than positives or neutrals so, maybe an ovr that compares class by class won't be the best choice."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm gonna preprocess the data to reduce dimensionality as well as see how well the model does. In case that we obtain poor results we could always change this function and try to prepare the data in a better way. For our case we tried both erasing only the punctuation as well as erasing the stopwords and we had a better result going for the simple. Remember that here there are a lot of preocess that we can do, lemmatize, change the tokenization, word to index mapping... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "import string\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "def normalize_text(raw_text):\n",
    "    raw_text = str(raw_text).lower()\n",
    "    text = raw_text.translate(str.maketrans('','',string.punctuation))\n",
    "    # text = nlp(text)\n",
    "    # final_token_list = [token for token in text if token.is_stop == False]\n",
    "    # final_text_list = [token.text for token in final_token_list]\n",
    "    # text_processed = \" \".join(final_text_list)\n",
    "    \n",
    "    # return text_processed\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(lambda x: normalize_text(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now our texts won't have any punctuation nor problematic and useless characters. Now it comes the moment to turn words into vectors. In order to vectorize is useful to try different strategies. In ur case we used both CountVectorizer as well as the TfIdf and the first one gave us better resutls so we just kept it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14640, 16632)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "# vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(df['Text'])\n",
    "vectors.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always we divide out train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(vectors, df['Label'], test_size=0.10, random_state=111)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when it comes to use LogisticRegression for multiclassification tasks there are 2 possibilities. The ovr which goes class by class comparing with the other classes or the multinominal which goes directly with all the classes. Again the better way I think is to try both and check the results. About how to adjust the parameters there is tons of information in internet. In our case we used theses posts. \n",
    "\n",
    "https://www.kaggle.com/code/satishgunjal/multiclass-logistic-regression-using-sklearn/notebook\n",
    "https://pub.towardsai.net/logistic-regression-for-multi-class-classification-hands-on-with-scikit-learn-bcc0bbad1def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# model = LogisticRegression(multi_class='multinomial',solver='lbfgs', penalty='l2',max_iter=1000)\n",
    "model = LogisticRegression(multi_class='ovr',solver='lbfgs',max_iter=1000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While fitting the model you muight run into this error.\n",
    "\n",
    "        ConvergenceWarning: lbfgs failed to converge (status=1):\n",
    "        STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
    "\n",
    "        Increase the number of iterations (max_iter) or scale the data as shown in:\n",
    "            https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "        Please also refer to the documentation for alternative solver options:\n",
    "            https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
    "          n_iter_i = _check_optimize_result(\n",
    "\n",
    "THis means that not all the vectors have been stored by a memory issue, but the best approximation possible is stored and that will be used. In order to solve it the best way is to increase the number of iterations. In our case to 1000 .\n",
    "More information here.\n",
    "\n",
    "https://stackoverflow.com/questions/62658215/convergencewarning-lbfgs-failed-to-converge-status-1-stop-total-no-of-iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(variable_with_model, vectors_of_training, labels_of_training):\n",
    "    variable_with_model.fit(vectors_of_training, labels_of_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model,X_train,y_train)\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set score: 0.933060\n",
      "test set score: 0.824454\n",
      "coefficients shape:  (3, 16632)\n",
      "intercept shape:  (3,)\n"
     ]
    }
   ],
   "source": [
    "#Evaluate Logistic Regression model:\n",
    "print(\"training set score: %f\" % model.score(X_train, y_train))\n",
    "print(\"test set score: %f\" % model.score(X_test, y_test))\n",
    "print(\"coefficients shape: \", model.coef_.shape)\n",
    "print(\"intercept shape: \", model.intercept_.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well now is the time to interpret our results and make changes if needed. In our case tha classes were imbalanced so accuracy probably won't be a very good metric. Going by the book the F1_score is the most common so we're gonna go for it.\n",
    "\n",
    "When working with f1_score with different classes we found this tutorial quite useful: https://www.baeldung.com/cs/multi-class-f1-score\n",
    "\n",
    "Normally with the F1_score in a multiclassification problem we calculate the F1_score per class and, after that's done we can go to make calculations with the total of values fo the different classes.\n",
    "In order to do so we can go by doing the following: \n",
    "\n",
    "we import the metric of f1_score and put the average parameter to 'None'. This way it will gave us back the f1 score as a list containing the values for all of the three classes. Remember that, in order to use the function we give as arguments the real values of test set as well as the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88745288 0.67192429 0.77803204]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "F1 = f1_score(y_test,pred,average=None)\n",
    "print(F1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a 0.82 aproximately. But, what if we want to have just a single number?, in that case we use these 3 values to make different averages. They will be exaplined in comments in the same cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8244535519125683\n"
     ]
    }
   ],
   "source": [
    "# micro calculates positive and negative values globally\n",
    "F1 = f1_score(y_test,pred,average='micro')\n",
    "print(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7791364026083127\n"
     ]
    }
   ],
   "source": [
    "# macro, take the average of each class’s F-1 score\n",
    "F1 = f1_score(y_test,pred,average='macro')\n",
    "print(F1)\n",
    "# Note that the macro method treats all classes as equal, independent of the sample sizes which is not ideal since we have imbalance classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8221241034699063\n"
     ]
    }
   ],
   "source": [
    "# The class F-1 scores are averaged by using the number of instances in a class as weights\n",
    "F1 = f1_score(y_test,pred,average='weighted')\n",
    "print(F1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there are different metrics that we can use. For our problem seems that weighted is the most adequate one since we have imbalanced classes but maybe your client wouldn't be happy with theses numbers so you will have to ask for a more balanced datasets, or change the preprocess or even the algorithm that you're using. The metrics only gave us numbers, is up to the project requirements as well as the Data science team to evaluate and take the decisions needed for the problem at hand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
